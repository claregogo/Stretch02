---
title: "Data Science for Public Policy"
subtitle: "Stretch 02"
author: "Zehui Li, Mujin Li"
execute:
  warning: false
format:
  html:
    embed-resources: true
---

## 1. set up

### library

```{r}
library(mice) # for imputating missing value
library(dplyr)
library(here)
library(withr)
library(tidyverse)
library(lubridate)
library(tidymodels)
library(themis)
library(recipes)
library(parsnip)
library(ranger)
library(ggplot2)
library(vip)
library(patchwork)
library(readr)       # for importing data
```

### data setup

[data from tidytuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-05-09/readme.md)

```{r}
# All packages used in this script:


url <- "https://www.dol.gov/sites/dolgov/files/WB/media/nationaldatabaseofchildcareprices.xlsx"
temp_xlsx <- withr::local_tempfile(fileext = ".xlsx")
download.file(url, temp_xlsx, mode = "wb")

childcare_costs_raw <- readxl::read_xlsx(temp_xlsx) |>
  janitor::clean_names() |> 
  # There are 15 constant columns. Get rid of those.
  janitor::remove_constant(quiet = FALSE)

# The file is very large, but it contains a lot of duplicate data. Extract
# duplications into their own tables.
counties <- childcare_costs_raw |> 
  dplyr::distinct(county_fips_code, county_name, state_name, state_abbreviation)
childcare_costs <- childcare_costs_raw |> 
  dplyr::select(
    -county_name,
    -state_name,
    -state_abbreviation,
    # Original data also contained unadjusted + adjusted dollars, let's just
    # keep the 2018 adjustments.
    -mhi, -me, -fme, -mme,
    # A number of columns have fine-grained breakdowns by age, and then also
    # broader categories. Let's only keep the categories ("infant" vs 0-5
    # months, 6-11 monts, etc)
    -ends_with("bto5"), -ends_with("6to11"), -ends_with("12to17"), 
    -ends_with("18to23"), -ends_with("24to29"), -ends_with("30to35"),
    -ends_with("36to41"), -ends_with("42to47"), -ends_with("48to53"),
    -ends_with("54to_sa"),
    # Since we aren't worrying about the unaggregated columns, we can ignore the
    # flags indicating how those columns were aggregated into the combined
    # columns.
    -ends_with("_flag"),
    # Original data has both median and 75th percentile for a number of columns.
    # We'll simplify.
    -starts_with("x75"),
    # While important for wider research, we don't need to keep the (many)
    # variables describing whether certain data was imputed.
    -starts_with("i_")
  )
```

### Split the data into training and testing data

predictor: Center-Based Care for those who are school age based

```{r}
childcare_costs<- subset(childcare_costs, select = -c(mfccsa, mc_infant, mc_toddler, mc_preschool, mfcc_infant, mfcc_toddler, mfcc_preschool))
childcare_costs<-childcare_costs%>%
  rename(county = county_fips_code)

childcare_costs%>%
  group_by(county)%>%
  summarise(missing_values = sum(is.na(mcsa)))

# use mean value to fill missing value
childcare_costs$h_under6_single_m <- ifelse(is.na(childcare_costs$h_under6_single_m), mean(childcare_costs$h_under6_single_m, na.rm = TRUE), childcare_costs$h_under6_single_m)
childcare_costs$h_6to17_single_m <- ifelse(is.na(childcare_costs$h_6to17_single_m), mean(childcare_costs$h_6to17_single_m, na.rm = TRUE), childcare_costs$h_6to17_single_m)
# pick out the rows includes the missing value 
implement <- childcare_costs[is.na(childcare_costs$mcsa), ]
childcare_modeling <- childcare_costs[complete.cases(childcare_costs), ]
# examine the missing value
childcare_modeling %>%
  summarise_all(~ sum(is.na(.)))
glimpse(childcare_costs$mcsa)
```

split data into train and test

```{r}
set.seed(701)
split <-initial_split(childcare_modeling)
train<-training(split)
test<-testing(split)
```

set resample

```{r}
set.seed(234)
folds<-vfold_cv(train, v = 10)
```

## 2.come up with models

### create recipe

```{r}
recipe<-recipe(mcsa~.,data = train)%>%
  step_dummy(all_nominal_predictors())%>%
  step_zv(all_predictors()) %>% 
  step_impute_knn(all_predictors())%>%
  step_scale(all_numeric_predictors())
bake(prep(recipe, training = train),new_data = train)
```

### lasso with penalty

```{r}
# use Cross-Validation
lasso_grid <- grid_regular(penalty(), levels = 1000)
lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1
) %>%
  set_engine("glmnet", path_values = lasso_grid$penalty)
#create the workflow
lasso_wf<-
  workflow()%>%
  add_model(lasso_mod)%>%
  add_recipe(recipe)
#train and tune the model
lasso_res <- 
  lasso_wf %>% 
  tune_grid(folds,
            grid = lasso_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
# plot the visulization of penalty and rmse
lasso_rmse<-
  collect_metrics(lasso_res, summarize = FALSE) %>% 
  filter(.metric == "rmse") 

lasso_plot <-ggplot(lasso_rmse, aes(x = penalty, y = .estimate,color = id)) +
  geom_line() +
  geom_point() +
  scale_x_log10(labels = scales::label_number())+
  labs(title = "RMSE Across Lasso Resamples",
       x = "penalty",
       y = "RMSE") +
  theme_minimal()

lasso_plot 
```

### random forest

```{r}
#use the parallel package to query the number of cores on my computer 
cores <- parallel::detectCores()
cores
#build the model
rf_mod <- 
  rand_forest(mtry = tune(), min_n = tune(), trees = 500) %>% 
  set_engine("ranger",num.threads = 10) %>% 
  set_mode("regression")
#create the workflow
rf_wf <- 
  workflow() %>% 
  add_model(rf_mod) %>% 
  add_recipe(recipe)
#
set.seed(345)
rf_res <- 
  rf_wf %>% 
  tune_grid(folds,
            grid = 5,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(rmse))
#
rf_res %>% 
  show_best(metric = "rmse")


```
